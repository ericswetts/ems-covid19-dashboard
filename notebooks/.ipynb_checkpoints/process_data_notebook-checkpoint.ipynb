{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import json\n",
    "from csv import writer\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "import plotly.express as px\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#remove print limit to better explore dataframe data\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to make API call\n",
    "def make_api_call():\n",
    "    response = requests.get('https://coronavirus-tracker-api.herokuapp.com/v2/locations?timelines=1')\n",
    "    timeline_json = response.json()\n",
    "    \n",
    "    try:\n",
    "        with open('../api_data/timeline_json.json', 'w') as f:\n",
    "          json.dump(timeline_json, f, ensure_ascii=False)\n",
    "        \n",
    "        #updating API log\n",
    "        update_api_log(date.today())\n",
    "        \n",
    "        return timeline_json\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Error making API call: ', e)\n",
    "\n",
    "#helper function to load previously loaded api data\n",
    "def use_existing_api_data():\n",
    "    try:\n",
    "        timeline_json = json.load(open('../api_data/timeline_json.json'))\n",
    "        return timeline_json\n",
    "    except Exception as e:\n",
    "        print('Error reading existing JSON file: ', e)\n",
    "\n",
    "#helper function to update api call log\n",
    "def update_api_log(date):\n",
    "    string_date = str(date)\n",
    "    try:\n",
    "        with open('../api_data/api_call_log.csv', 'a', newline='') as write_obj:\n",
    "            csv_writer = writer(write_obj)\n",
    "            csv_writer.writerow([string_date])\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error updating API log: ', e)\n",
    "        \n",
    "def up_to_date_check():\n",
    "    today = str(date.today())\n",
    "    log = pd.read_csv('../api_data/api_call_log.csv')\n",
    "    last = log.loc[:,'date'].max()\n",
    "    return last == today\n",
    "\n",
    "#helper function to load data (cached or via new API call) for webapp\n",
    "def get_raw_data():\n",
    "    raw_data = use_existing_api_data() if up_to_date_check else make_api_call()\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_data():\n",
    "\n",
    "#import ISO3 data for Dash Plotly Choropletyh mapping\n",
    "    iso3 = pd.read_csv(\"../geodata/ISO3.csv\",  index_col = 0)\n",
    "    location_data = get_raw_data()['locations']\n",
    "    \n",
    "    #create empty list to compile country-level data\n",
    "    data_rows = []\n",
    "\n",
    "    #Extract COVID morbidity and mortality data from COVID JSON\n",
    "    for loc in location_data:\n",
    "\n",
    "        #Remove non-countries and countries with missing data\n",
    "        if loc['country'] in ['MS Zaandam', 'Eritrea', 'Diamond Princess']: continue   \n",
    "\n",
    "        cases = [{'Date': k, 'Cases' :v} for k,v in loc['timelines']['confirmed']['timeline'].items()]\n",
    "        deaths = [{'Date': k, 'Deaths' :v} for k,v in loc['timelines']['deaths']['timeline'].items()]\n",
    "\n",
    "        country_data = pd.merge(\n",
    "            pd.DataFrame(deaths), \n",
    "            pd.DataFrame(cases), \n",
    "            left_on = 'Date', \n",
    "            right_on = 'Date')\n",
    "\n",
    "        country_data['Country'] = 'United States' if loc['country'] == 'US' else loc['country']\n",
    "        country_data['Country Code'] =  loc['country_code']\n",
    "        country_data['Population'] =  loc['country_population']\n",
    "        country_data['Province'] =  loc['province']\n",
    "        country_data['Latitude'], country_data['Longitude'] =  [*loc['coordinates'].values()]\n",
    "        country_data['Cases per 1M'] = (country_data['Cases'] /  country_data['Population']* 1000000).round(1)\n",
    "        country_data['Deaths per 1M'] = (country_data['Deaths'] /  country_data['Population']* 1000000).round(1)\n",
    "        country_data['Change in Deaths (n)'] = country_data['Deaths'].diff()\n",
    "        country_data['Change in Deaths (pct)'] = country_data['Deaths'].pct_change().round(2)\n",
    "        country_data['Multiple_Territories'] = country_data['Country'].isin(['China', 'Canada', 'United Kingdom', 'France', 'Australia', 'Netherlands', 'Denmark'])\n",
    "        \n",
    "        #Date-related Variables\n",
    "        country_data['Date'] =  pd.to_datetime(country_data['Date'].str.slice(0,10)) # + \" \" + country_data['Date'].str.slice(11, -1)\n",
    "        country_data['Month and Year'] = pd.DatetimeIndex(country_data['Date']).strftime(\"%b %Y\")\n",
    "        # Later joined to dates on first of each month to create data labels\n",
    "        country_data['Day'] = pd.DatetimeIndex(country_data['Date']).strftime('%-d')\n",
    "        \n",
    "        data_rows.append(country_data)\n",
    "\n",
    "    df_cases = pd.concat(data_rows, axis = 0)\n",
    "    \n",
    "    #Merge ISO-3 country codes for cholopleth mapping\n",
    "    processed_data = pd.merge(df_cases, iso3, left_on = 'Country', right_on = 'Country', how = 'left')\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Country and Date, to sum metrics (cases, deaths, etc.)\n",
    "# for countries with multiple provinces listed. This allows our graphs \n",
    "# to render country-level statistics\n",
    "\n",
    "def get_chart_ready_df():\n",
    "    df = process_raw_data()\n",
    "\n",
    "    chart_ready_df = df.groupby(\n",
    "                        ['Country', \n",
    "                        'Population', \n",
    "                        'Date', \n",
    "                        'ISO-3', \n",
    "                        'Multiple_Territories',\n",
    "                        'Month and Year',\n",
    "                        'Day']\n",
    "                    ).agg({\n",
    "                        'Deaths':'sum',\n",
    "                        'Deaths per 1M':'sum',\n",
    "                        'Cases': 'sum',\n",
    "                        'Cases per 1M' : 'sum'\n",
    "                    }).reset_index()\n",
    "\n",
    "    chart_ready_df.to_csv('../api_data/chart_ready.csv')\n",
    "    return chart_ready_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
